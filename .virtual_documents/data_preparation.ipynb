





import pandas as pd


%run ./definitions.ipynb


eod_prices = pd.read_csv(eod_price_file_csv)
eod_prices.rename(columns={'Date': 'date'}, inplace=True)
eod_prices.head(10)



import plotly.graph_objects as go
from datetime import datetime

fig = go.Figure(data=[go.Candlestick(x=eod_prices['date'],
                open=eod_prices['Open'],
                high=eod_prices['High'],
                low=eod_prices['Low'],
                close=eod_prices['Close'])])

fig.update_layout(
    title={
        'text': f"{ticker} EOD Prices",
        'x': 0.5, # (0.5 is centered)
        'y': 0.90,
        'xanchor': 'center', 
        'yanchor': 'top',  
        'font':{'size':20, 'color':'blue', 'family':'Arial'}
    }
)

fig.show()


import pandas as pd
import plotly.express as px

# Load the CSV file into a DataFrame
df = pd.read_csv(eod_price_file_csv)

# Convert 'Volume' to numeric, coercing errors to NaN
df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')
df = df.dropna(subset=['Volume'])
df = df.sort_values(by='Date')

# Create a Plotly line plot for Volume vs. Date
fig = px.line(df, x='Date', y='Volume')

fig.update_layout(
    title={
        'text': f"{ticker} EOD Volumes",
        'x': 0.5, # (0.5 is centered)
        'y': 0.95,
        'xanchor': 'center', 
        'yanchor': 'top',  
        'font':{'size':20, 'color':'blue', 'family':'Arial'}
    }
)

# Show the plot
fig.show()






news = pd.read_json(finacial_news_file_json)
news.head(10)


print(f'before filtering title column: {news.shape}')





news = news[news['title'].str.contains('tesla|musk|elon', case=False, na=False)]


 print(f'after filtering title column: {news.shape}')





news[['polarity', 'neg', 'neu', 'pos']] = news['sentiment'].apply(pd.Series)
news = news.drop('sentiment', axis=1)
news.head(10)





import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Initialize NLTK data needed for stop words and lemmatization
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('punkt_tab')

def clean_text(text):
    # Convert to lowercase
    text = text.lower()
    
    # Remove special characters and punctuation
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    
    # Tokenize the text
    tokens = nltk.word_tokenize(text)
    
    # Remove stop words
    stop_words = set(stopwords.words('english'))
    tokens = [t for t in tokens if t not in stop_words]
    
    # Lemmatize the tokens
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(t) for t in tokens]
    
    # Join the tokens back into a string
    cleaned_text = ' '.join(tokens)
    
    return cleaned_text

# Example usage
text = "The 3 Most Undervalued S&amp;P 500 Stocks"
cleaned_txt = clean_text(text)
print(cleaned_txt)

news['title_cleaned'] = news['title'].apply(clean_text)
news['content_cleaned'] = news['content'].apply(clean_text)
news.head(10)





from transformers import pipeline

# Create a pipeline for text classification using a pre-trained model
# Note the log "Device set to use mps:0", which means that PyTorch is using the Metal Performance Shaders (MPS) backend on an Apple Silicon device.
# Device mps:0: This refers to the first available MPS device. In most cases, there will only be one MPS device available on a single Apple Silicon chip.print(f'example: {pipe(text)}')

pipe = pipeline("text-classification", model="mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis")

def analyze_sentiment(text):
    '''
    The default maximal number of tokens is 512 and this function will through an exception if the number of tokens in the text exceeds this limit.
    Truncating the text to at most 2000 characters is the quickest workaround.
    This fix is based on the assumption that a news sentiment is typically conveyed right away at the beginning of the article.
    TODO: Check how to increase the maximal number of tokens in the model configration.
    '''
    max_length = 2000
    if len(text) > max_length:
        text = text[:max_length]
    result = pipe(text)
    # Extract the sentiment label and score
    label = result[0]['label']
    score = result[0]['score']
    return label, score


# Perform sentiment analysis
print('.'*40, 'analyzing titles')
news[['title_label', 'title_score']] = news['title_cleaned'].apply(lambda x: pd.Series(analyze_sentiment(x)))

print('.'*40, 'analyzing contents')
news[['content_label', 'content_score']] = news['content_cleaned'].apply(lambda x: pd.Series(analyze_sentiment(x)))
news.head(10)



news.to_csv(finacial_news_file_csv, index=False)


import pandas as pd
import plotly.graph_objects as go

df = news


# Convert date column to datetime
df['date'] = pd.to_datetime(df['date'])

# Create the figure
fig = go.Figure()

# Add traces for each sentiment
fig.add_trace(go.Scatter(x=df['date'], y=df['polarity'], name='Polarity'))
fig.add_trace(go.Scatter(x=df['date'], y=df['neg'], name='Negative'))
fig.add_trace(go.Scatter(x=df['date'], y=df['neu'], name='Neutral'))
fig.add_trace(go.Scatter(x=df['date'], y=df['pos'], name='Positive'))

# Update layout
fig.update_layout(
    title={
        'text': f"{ticker} News Sentiment Content (original values from eodhd)",
        'x': 0.5, # (0.5 is centered)
        'y': 0.90,
        'xanchor': 'center', 
        'yanchor': 'top',  
        'font':{'size':20, 'color':'blue', 'family':'Arial'}
    },
    xaxis_title='Date',
    yaxis_title='Score'
)


fig.show()



import pandas as pd
import plotly.express as px

df = news 

# Convert date column to datetime
df['date'] = pd.to_datetime(df['date'])

# Create the plot
fig = px.scatter(df, x='date', y='title_score', color='title_label')
fig.update_xaxes(title='Date')
fig.update_yaxes(title='Title Score')
fig.update_traces(marker=dict(opacity=0.5))

fig.update_layout(
    title={
        'text': f"{ticker} News Sentiment Title",
        'x': 0.5, # (0.5 is centered)
        'y': 0.95,
        'xanchor': 'center', 
        'yanchor': 'top',  
        'font':{'size':20, 'color':'blue', 'family':'Arial'}
    },
    xaxis_title='Date',
    yaxis_title='Score'
)

fig.show()



import pandas as pd
import plotly.express as px

df = news 

# Create the plot
fig = px.scatter(df, x='date', y='content_score', color='content_label')
fig.update_xaxes(title='Date')
fig.update_yaxes(title='Content Score')
fig.update_traces(marker=dict(opacity=0.5))

fig.update_layout(
    title={
        'text': f"{ticker} News Sentiment Content (recalculated)",
        'x': 0.5, # (0.5 is centered)
        'y': 0.95,
        'xanchor': 'center', 
        'yanchor': 'top',  
        'font':{'size':20, 'color':'blue', 'family':'Arial'}
    },
    xaxis_title='Date',
    yaxis_title='Score'
)

fig.show()





news = pd.read_csv(finacial_news_file_csv)
news.head(5)


print(news['date'].dtype)
news['date'] = pd.to_datetime(news['date'], errors='coerce')
print(news['date'].dtype)
news['date'] = news['date'].dt.strftime('%Y-%m-%d')
news.head(5)


news_avg_polarity = news.groupby('date')['polarity'].mean().reset_index()
news_avg_polarity.head(10)
news_avg_polarity.tail(10)





combined_data = pd.merge(eod_prices, news_avg_polarity, on='date', how='left')
combined_data.columns = combined_data.columns.str.lower()
combined_data.head(5)





combined_data.to_csv(combined_data_file_csv, index=False)



