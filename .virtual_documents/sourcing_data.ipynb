


import re
import requests
import pandas as pd
import config as cfg
from eodhd import APIClient

import datetime
from IPython.display import display, clear_output





!mkdir data





import os
from dotenv import load_dotenv

load_dotenv()
EODHD_API_KEY = os.getenv("EODHD_API_KEY")





def fetch_historical_news(ticker, months):
    """Fetches historical news for the given ticker over the past specified months."""
    
    BASE_URL = "https://eodhd.com/api/news"
    
    end_date = datetime.datetime.today()
    start_date = end_date - datetime.timedelta(days=30 * months)
    
    all_news = []
    offset = 0

    i = 0
    while True:
        params = {
            "s": ticker,  
            "limit": LIMIT,
            "offset": offset,
            "api_token": EODHD_API_KEY,
            "from": start_date.strftime("%Y-%m-%d"),
            "to": end_date.strftime("%Y-%m-%d"),
        }
        
        response = requests.get(BASE_URL, params=params)
        
        if response.status_code != 200:
            print("Error fetching data:", response.text)
            break

        data = response.json()

        if not data:  # Stop when no more news is returned
            break
        
        all_news.extend(data)
        offset += LIMIT  # Increase offset for pagination
        print(i, len(data))
        i += 1

    return all_news





def fetch_historical_prices(ticker, months):
    """Fetches historical EOD prices for the given ticker over the past specified months."""
    
    BASE_URL = f"https://eodhd.com/api/eod/{TICKER}"  # EOD API endpoint
    
    end_date = datetime.datetime.today()
    days = 30 * months
    start_date = end_date - datetime.timedelta(days=30 * months)
    
    all_prices = []
    offset = 0

    i = 0
    for i in range(days):
        params = {
            "limit": LIMIT,
            "offset": offset,
            "api_token": EODHD_API_KEY,
            "from": start_date.strftime("%Y-%m-%d"),
            "to": end_date.strftime("%Y-%m-%d"),
            "order": "d",  # Order by descending (newest first)
        }
        
        response = requests.get(BASE_URL, params=params)

        data = response.text
        clear_output(wait=True)
        display(f'{i} {len(data)}')
        
        all_prices += data
        offset += LIMIT  # Increase offset for pagination

    return all_prices






TICKER = "TSLA"
LIMIT = 1000  # Maximum per request
months = 12


# Fetch the past n months of news for ticker
news_data = fetch_historical_news(ticker=TICKER, 
                                  months=months)

# Print number of articles fetched
print(f"Total articles fetched: {len(news_data)}")
print('-'*80)
# Print the first few articles
for article in news_data[:5]:  
    print(article["title"], "-", article["date"])



import json

f_path = f'./data/{TICKER.lower()}_financial_news.json'
with open(f_path, 'w') as f:
    json.dump(news_data, f, indent=4)


df = pd.read_json(f_path)
df.shape


df.head()





# Fetch past n months of stock prices for ticker
price_data = fetch_historical_prices(ticker=TICKER, 
                                     months=months)

# Print total number of records fetched
print(f"Total records fetched: {len(price_data)}")



import pprint as pp
pp.pprint(''.join(price_data[:100]))
print()
pp.pprint(''.join(price_data[-100:]))


all_prices = ''.join(price_data)


from io import StringIO

s = StringIO(all_prices)
f_name = f'./data/{TICKER.lower()}_eod_prices.csv'
with open(f_name, 'w') as f:
    for line in s:
        f.write(line)


!ls -ltr ./data
